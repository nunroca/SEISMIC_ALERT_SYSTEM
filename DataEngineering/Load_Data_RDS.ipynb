<<<<<<< HEAD
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIBRERIAS NECESARIAS:\n",
    "#Para utilizar API\n",
    "import requests\n",
    "#Para realizar la estructura tabular\n",
    "import pandas as pd\n",
    "#Para rellenar vacíos\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "#ETL:\n",
    "\n",
    "#para normalizar strings\n",
    "from unicodedata import normalize\n",
    "#para normalizar incluyendo la ñ\n",
    "import re \n",
    "#para normalizar fechas\n",
    "import datetime\n",
    "#para obtener fechas\n",
    "import time\n",
    "#hacer los calendarios de iteración\n",
    "from dateutil.rrule import rrule, DAILY , MONTHLY\n",
    "\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "#para normalizar fechas\n",
    "from datetime import datetime\n",
    "#para obtener fechas\n",
    "import time\n",
    "\n",
    "dic={}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 20px; color:cyan; font-weight: bold;\"> - Conexión al  servidos RDS</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"database-alertas-sismicas.crcnepco0igw.us-east-1.rds.amazonaws.com\"\n",
    "user = \"admin\"\n",
    "password = \"admin4168\"\n",
    "database = \"alertasSismicas\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "con=create_engine(f\"mysql+mysqlconnector://{user}:{password}@{host}/{database}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = mysql.connector.connect(\n",
    "    host=host,\n",
    "    user=user,\n",
    "    password=password,\n",
    "    database=database\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 20px; color:cyan; font-weight: bold;\"> - Creation of data tables.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_countries = 'DROP TABLE IF EXISTS COUNTRIES CASCADE; CREATE TABLE COUNTRIES (idcountry INTEGER AUTO_INCREMENT PRIMARY KEY NOT NULL ,country text);'\n",
    "data_jap = 'DROP TABLE IF EXISTS JAPAN CASCADE; CREATE TABLE JAPAN (idsismo SERIAL PRIMARY KEY NOT NULL,idcountry INTEGER,foreign key (idcountry) references COUNTRIES(idcountry),mag float8, place text,time timestamp,tsunami text,lng float8, lat float8,depth float8, danger smallint);'\n",
    "data_usa = 'DROP TABLE IF EXISTS USA CASCADE; CREATE TABLE USA (idsismo SERIAL PRIMARY KEY NOT NULL,idcountry INTEGER,foreign key (idcountry) references COUNTRIES(idcountry),mag float8, place text,time timestamp,tsunami text,lng float8, lat float8,depth float8, danger smallint);'\n",
    "data_chile = 'DROP TABLE IF EXISTS CHILE CASCADE; CREATE TABLE CHILE (idsismo SERIAL PRIMARY KEY NOT NULL,idcountry INTEGER,foreign key (idcountry) references COUNTRIES(idcountry),mag float8, place text,time timestamp,tsunami text,lng float8, lat float8,depth float8, danger smallint);'\n",
    "data_fact = 'DROP TABLE IF EXISTS FACTS CASCADE; CREATE TABLE FACTS (idsismo SERIAL PRIMARY KEY NOT NULL,idcountry INTEGER,foreign key (idcountry) references COUNTRIES(idcountry),mag float8, place text,time timestamp,tsunami text,lng float8, lat float8,depth float8, danger smallint);'\n",
    "data_tsu = 'DROP TABLE IF EXISTS TSUNAMIS CASCADE; CREATE TABLE TSUNAMIS (id SERIAL PRIMARY KEY NOT NULL ,idcountry INTEGER,foreign key (idcountry) references COUNTRIES(idcountry),mxwatheight float8, place text, time timestamp, mag float8, lng float8, lat float8, depth float8);'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor=connection.cursor()\n",
    "cursor.execute(data_countries)\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor=connection.cursor()\n",
    "cursor.execute(data_jap)\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor=connection.cursor()\n",
    "cursor.execute(data_chile)\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor=connection.cursor()\n",
    "cursor.execute(data_usa)\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor=connection.cursor()\n",
    "cursor.execute(data_fact)\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor=connection.cursor()\n",
    "cursor.execute(data_tsu)\n",
    "cursor.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 20px; color:cyan; font-weight: bold;\"> - Development of the Countries table. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def COUNTRIES(country):\n",
    "\n",
    "    global dic\n",
    "    if country in dic:\n",
    "        #df.to_sql(name='pais',con=cone, if_exists='replace', index=False)\n",
    "        return(dic[country])\n",
    "    else:\n",
    "        dic[country]=len(dic)+1\n",
    "        dic_pais={'COUNTRY':[country]}\n",
    "        df=pd.DataFrame(dic_pais)\n",
    "        df.to_sql(name='COUNTRIES',con=con, if_exists='append', index=False)\n",
    "        \n",
    "        return(dic[country])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COUNTRIES(\"USA\")\n",
    "COUNTRIES(\"CHILE\")\n",
    "COUNTRIES(\"JAPAN\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fechas():\n",
    "\n",
    "    #Fecha inicio\n",
    "    a = datetime.date(2022, 1, 1)\n",
    "    #Fecha fin\n",
    "    b = datetime.date.today()\n",
    "    return a,b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 20px; color:cyan; font-weight: bold;\"> - Development of the Historic table. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 503: Service Unavailable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m url_japan \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://earthquake.usgs.gov/fdsnws/event/1/query?format=csv&starttime=2010-01-01%2000:00:00&endtime=2023-12-31%2023:59:59&minlatitude=27.000000&maxlatitude=44.000000&minlongitude=132.780000&maxlongitude=145.530000&minmagnitude=3&orderby=time-asc&jsonerror=true\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m dt_in_jap\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39;49mread_csv(url_japan,delimiter\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m url_chile \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://earthquake.usgs.gov/fdsnws/event/1/query?format=csv&starttime=2010-01-01%2000:00:00&endtime=2023-12-31%2023:59:59&minlatitude=-56.800000&maxlatitude=-19.000000&minlongitude=-79.000000&maxlongitude=-69.&minmagnitude=3&orderby=time-asc&jsonerror=true\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      4\u001b[0m dt_in_ch\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mread_csv(url_chile,delimiter\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:716\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    713\u001b[0m     codecs\u001b[39m.\u001b[39mlookup_error(errors)\n\u001b[0;32m    715\u001b[0m \u001b[39m# open URLs\u001b[39;00m\n\u001b[1;32m--> 716\u001b[0m ioargs \u001b[39m=\u001b[39m _get_filepath_or_buffer(\n\u001b[0;32m    717\u001b[0m     path_or_buf,\n\u001b[0;32m    718\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m    719\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m    720\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m    721\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m    722\u001b[0m )\n\u001b[0;32m    724\u001b[0m handle \u001b[39m=\u001b[39m ioargs\u001b[39m.\u001b[39mfilepath_or_buffer\n\u001b[0;32m    725\u001b[0m handles: \u001b[39mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:368\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[39m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[0;32m    367\u001b[0m req_info \u001b[39m=\u001b[39m urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[39m=\u001b[39mstorage_options)\n\u001b[1;32m--> 368\u001b[0m \u001b[39mwith\u001b[39;00m urlopen(req_info) \u001b[39mas\u001b[39;00m req:\n\u001b[0;32m    369\u001b[0m     content_encoding \u001b[39m=\u001b[39m req\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mContent-Encoding\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    370\u001b[0m     \u001b[39mif\u001b[39;00m content_encoding \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgzip\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    371\u001b[0m         \u001b[39m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:270\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[39mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[39mthe stdlib.\u001b[39;00m\n\u001b[0;32m    267\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39murllib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrequest\u001b[39;00m\n\u001b[1;32m--> 270\u001b[0m \u001b[39mreturn\u001b[39;00m urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39murlopen(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39;49mopen(url, data, timeout)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[39mfor\u001b[39;00m processor \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_response\u001b[39m.\u001b[39mget(protocol, []):\n\u001b[0;32m    524\u001b[0m     meth \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 525\u001b[0m     response \u001b[39m=\u001b[39m meth(req, response)\n\u001b[0;32m    527\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[39m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m code \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparent\u001b[39m.\u001b[39;49merror(\n\u001b[0;32m    635\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mhttp\u001b[39;49m\u001b[39m'\u001b[39;49m, request, response, code, msg, hdrs)\n\u001b[0;32m    637\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[39mif\u001b[39;00m http_err:\n\u001b[0;32m    562\u001b[0m     args \u001b[39m=\u001b[39m (\u001b[39mdict\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhttp_error_default\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m+\u001b[39m orig_args\n\u001b[1;32m--> 563\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    497\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhttp_error_default\u001b[39m(\u001b[39mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 643\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(req\u001b[39m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 503: Service Unavailable"
     ]
    }
   ],
   "source": [
    "url_japan = f'https://earthquake.usgs.gov/fdsnws/event/1/query?format=csv&starttime=2010-01-01%2000:00:00&endtime=2023-12-31%2023:59:59&minlatitude=27.000000&maxlatitude=44.000000&minlongitude=132.780000&maxlongitude=145.530000&minmagnitude=3&orderby=time-asc&jsonerror=true'\n",
    "dt_in_jap=pd.read_csv(url_japan,delimiter=',')\n",
    "url_chile = f'https://earthquake.usgs.gov/fdsnws/event/1/query?format=csv&starttime=2010-01-01%2000:00:00&endtime=2023-12-31%2023:59:59&minlatitude=-56.800000&maxlatitude=-19.000000&minlongitude=-79.000000&maxlongitude=-69.&minmagnitude=3&orderby=time-asc&jsonerror=true'\n",
    "dt_in_ch=pd.read_csv(url_chile,delimiter=\",\")\n",
    "url_usa = f'https://earthquake.usgs.gov/fdsnws/event/1/query?format=csv&starttime=2010-01-01%2000:00:00&endtime=2023-12-31%2023:59:59&maxlatitude=50&minlatitude=24.6&maxlongitude=-65&minlongitude=-125&minmagnitude=3&orderby=time-asc&jsonerror=true'\n",
    "dt_in_usa=pd.read_csv(url_usa,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformar_fecha(dato):\n",
    "    fecha_sin_tz = dato.replace(\"T\", \" \").replace(\"Z\", \"\")\n",
    "    fecha_objeto = datetime.strptime(fecha_sin_tz, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    fecha_formateada = fecha_objeto.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "    return fecha_formateada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generat_dat (df,pais:str):\n",
    "    df[\"place\"]=df[\"place\"].fillna(\"no data\")\n",
    "    df=df.fillna(0)\n",
    "    df=df.drop_duplicates()\n",
    "    df=df[[\"mag\",\"place\",\"time\",\"longitude\",\"latitude\",\"depth\"]]\n",
    "    df['time'] = df['time'].apply(lambda x: transformar_fecha(x))\n",
    "    df.rename(columns={'latitude':'lat', 'longitude':'lng' }, inplace=True)\n",
    "    df[\"idcountry\"]=COUNTRIES(pais)\n",
    "    df[\"tsunami\"]=1\n",
    "    df[\"danger\"]=\"1\"\n",
    "    df=df[[\"idcountry\",\"mag\",\"place\",\"time\",\"tsunami\",\"lng\",\"lat\",\"depth\",\"danger\"]]\n",
    "    \n",
    "       \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_his_usa=generat_dat(dt_in_usa,\"USA\")\n",
    "dt_his_chil=generat_dat(dt_in_ch,\"CHILE\")\n",
    "dt_his_jap=generat_dat(dt_in_jap,\"JAPAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14715"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_his_usa.to_sql(name='USA',con=con, if_exists='append', index=False)\n",
    "dt_his_usa.to_sql(name='FACTS',con=con, if_exists='append', index=False)\n",
    "\n",
    "dt_his_chil.to_sql(name='CHILE',con=con, if_exists='append', index=False)\n",
    "dt_his_chil.to_sql(name='FACTS',con=con, if_exists='append', index=False)\n",
    "\n",
    "dt_his_jap.to_sql(name='JAPAN',con=con, if_exists='append', index=False)\n",
    "dt_his_jap.to_sql(name='FACTS',con=con, if_exists='append', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 20px; color:cyan; font-weight: bold;\"> - Generate data from tsunamis. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'https://www.ngdc.noaa.gov/hazel/hazard-service/api/v1/tsunamis/events?country=USA&maxYear=2023&minYear=2010'\n",
    "dt_usa_prev_Mar = pd.DataFrame(requests.get(url).json()['items'])\n",
    "\n",
    "url = f'https://www.ngdc.noaa.gov/hazel/hazard-service/api/v1/tsunamis/events?country=JAPAN&maxYear=2023&minYear=2010'\n",
    "dt_jap_prev_Mar = pd.DataFrame(requests.get(url).json()['items'])\n",
    "\n",
    "url = f'https://www.ngdc.noaa.gov/hazel/hazard-service/api/v1/tsunamis/events?country=CHILE&maxYear=2023&minYear=2010'\n",
    "dt_chi_prev_Mar = pd.DataFrame(requests.get(url).json()['items'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mar(df):\n",
    "    \n",
    "    df=df.fillna(0)\n",
    "    df['time'] = pd.to_datetime(df[['year','month','day','hour','minute','second']],format='%Y/%m/%d %H:%M:%S')\n",
    "    df['time'] =df['time'].apply(lambda x: x.strftime('%Y/%m/%d %H:%M:%S'))\n",
    "    df.rename(columns={'eqMagnitude':'mag', 'eqDepth':'depth', 'latitude':'lat', 'longitude':'lng',\n",
    "    'locationName':'place', 'maxWaterHeight':'mxwatheight'}, inplace=True)\n",
    "\n",
    "\n",
    "    df['mxwatheight']  = df.mxwatheight.astype('float64')\n",
    "    df.mag=df.mag.astype('float64')\n",
    "    df.lng=df.lng.astype('float64')\n",
    "    df.lat=df.lat.astype('float64')\n",
    "    df.depth=df.depth.astype('float64')\n",
    "\n",
    "    a=df[\"country\"][1]\n",
    "    df[\"idcountry\"]=COUNTRIES(a)\n",
    "    \n",
    "    # Filtramos el dataframe con los datos relevantes.\n",
    "    df = df[['idcountry','mxwatheight','place', 'time', 'mag', 'lng','lat', 'depth' ]]\n",
    "    \n",
    "    return (df)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_usa_Mar=mar(dt_usa_prev_Mar)\n",
    "dt_chi_Mar=mar(dt_chi_prev_Mar)\n",
    "dt_jap_Mar=mar(dt_jap_prev_Mar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_usa_Mar.to_sql(name='TSUNAMIS',con=con, if_exists='append', index=False)\n",
    "dt_chi_Mar.to_sql(name='TSUNAMIS',con=con, if_exists='append', index=False)\n",
    "dt_jap_Mar.to_sql(name='TSUNAMIS',con=con, if_exists='append', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 20px; color:cyan; font-weight: bold;\"> - Falta funciòn nomralizacion tsunamis. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "consulta=\"SELECT * FROM TSUNAMIS\"\n",
    "df13=pd.read_sql_query(consulta,con)\n",
    "#connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=\"CHILE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2010-01-06 02:11:05\n",
       "1      2010-01-06 09:26:55\n",
       "2      2010-01-06 22:41:54\n",
       "3      2010-01-07 14:35:26\n",
       "4      2010-01-09 00:08:12\n",
       "               ...        \n",
       "9319   2023-05-13 04:51:25\n",
       "9320   2023-05-15 00:54:39\n",
       "9321   2023-05-15 06:18:33\n",
       "9322   2023-05-15 19:24:05\n",
       "9323   2023-05-16 00:53:39\n",
       "Name: time, Length: 9324, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consulta=\"SELECT * FROM \"+x+\" WHERE mag>0\"\n",
    "dfch=pd.read_sql_query(consulta,con)\n",
    "dfch[\"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "9319    0\n",
       "9320    0\n",
       "9321    0\n",
       "9322    0\n",
       "9323    0\n",
       "Name: time, Length: 9324, dtype: int32"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfch[\"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfch[\"time\"]=dfch[\"time\"].isin(df13[\"time\"]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=dfch[\"time\"].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
=======
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIBRERIAS NECESARIAS:\n",
    "#Para utilizar API\n",
    "import requests\n",
    "#Para realizar la estructura tabular\n",
    "import pandas as pd\n",
    "#Para rellenar vacíos\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "#ETL:\n",
    "\n",
    "#para normalizar strings\n",
    "from unicodedata import normalize\n",
    "#para normalizar incluyendo la ñ\n",
    "import re \n",
    "#para normalizar fechas\n",
    "import datetime\n",
    "#para obtener fechas\n",
    "import time\n",
    "#hacer los calendarios de iteración\n",
    "from dateutil.rrule import rrule, DAILY , MONTHLY\n",
    "\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "#para normalizar fechas\n",
    "from datetime import datetime\n",
    "#para obtener fechas\n",
    "import time\n",
    "\n",
    "dic={}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 20px; color:cyan; font-weight: bold;\"> - Conexión al  servidos RDS</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"database-alertas-sismicas.crcnepco0igw.us-east-1.rds.amazonaws.com\"\n",
    "user = \"admin\"\n",
    "password = \"admin4168\"\n",
    "database = \"alertasSismicas\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "con=create_engine(f\"mysql+mysqlconnector://{user}:{password}@{host}/{database}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = mysql.connector.connect(\n",
    "    host=host,\n",
    "    user=user,\n",
    "    password=password,\n",
    "    database=database\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 20px; color:cyan; font-weight: bold;\"> - Creation of data tables.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_countries = 'DROP TABLE IF EXISTS COUNTRIES CASCADE; CREATE TABLE COUNTRIES (idcountry INTEGER AUTO_INCREMENT PRIMARY KEY NOT NULL ,country text);'\n",
    "data_jap = 'DROP TABLE IF EXISTS JAPAN CASCADE; CREATE TABLE JAPAN (idsismo SERIAL PRIMARY KEY NOT NULL,idcountry INTEGER,foreign key (idcountry) references COUNTRIES(idcountry),mag float8, place text,time timestamp,tsunami text,lng float8, lat float8,depth float8, danger smallint);'\n",
    "data_usa = 'DROP TABLE IF EXISTS USA CASCADE; CREATE TABLE USA (idsismo SERIAL PRIMARY KEY NOT NULL,idcountry INTEGER,foreign key (idcountry) references COUNTRIES(idcountry),mag float8, place text,time timestamp,tsunami text,lng float8, lat float8,depth float8, danger smallint);'\n",
    "data_chile = 'DROP TABLE IF EXISTS CHILE CASCADE; CREATE TABLE CHILE (idsismo SERIAL PRIMARY KEY NOT NULL,idcountry INTEGER,foreign key (idcountry) references COUNTRIES(idcountry),mag float8, place text,time timestamp,tsunami text,lng float8, lat float8,depth float8, danger smallint);'\n",
    "data_fact = 'DROP TABLE IF EXISTS FACTS CASCADE; CREATE TABLE FACTS (idsismo SERIAL PRIMARY KEY NOT NULL,idcountry INTEGER,foreign key (idcountry) references COUNTRIES(idcountry),mag float8, place text,time timestamp,tsunami text,lng float8, lat float8,depth float8, danger smallint);'\n",
    "data_tsu = 'DROP TABLE IF EXISTS TSUNAMIS CASCADE; CREATE TABLE TSUNAMIS (id SERIAL PRIMARY KEY NOT NULL ,idcountry INTEGER,foreign key (idcountry) references COUNTRIES(idcountry),mxwatheight float8, place text, time timestamp, mag float8, lng float8, lat float8, depth float8);'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = 'DROP TABLE IF EXISTS SISMOTEST CASCADE; CREATE TABLE SISMOTEST (idsismo SERIAL PRIMARY KEY NOT NULL,idcountry INTEGER,foreign key (idcountry) references COUNTRIES(idcountry),mag float8, place text,time timestamp,tsunami text,lng float8, lat float8,depth float8, danger smallint);'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_alarm = 'DROP TABLE IF EXISTS ALARMS CASCADE;CREATE TABLE ALARMS (idsismo SERIAL PRIMARY KEY NOT NULL,idcountry INTEGER,foreign key (idcountry) references COUNTRIES(idcountry),mag float8, place text,time timestamp,tsunami text,lng float8, lat float8,depth float8, danger smallint);'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor=connection.cursor()\n",
    "cursor.execute(data_countries)\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor=connection.cursor()\n",
    "cursor.execute(data_jap)\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor=connection.cursor()\n",
    "cursor.execute(data_chile)\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor=connection.cursor()\n",
    "cursor.execute(data_usa)\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor=connection.cursor()\n",
    "cursor.execute(data_fact)\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor=connection.cursor()\n",
    "cursor.execute(data_tsu)\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor=connection.cursor()\n",
    "cursor.execute(data_test)\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor=connection.cursor()\n",
    "cursor.execute(data_alarm)\n",
    "cursor.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 20px; color:cyan; font-weight: bold;\"> - Development of the Countries table. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def COUNTRIES(country):\n",
    "\n",
    "    global dic\n",
    "    if country in dic:\n",
    "        #df.to_sql(name='pais',con=cone, if_exists='replace', index=False)\n",
    "        return(dic[country])\n",
    "    else:\n",
    "        dic[country]=len(dic)+1\n",
    "        dic_pais={'COUNTRY':[country]}\n",
    "        df=pd.DataFrame(dic_pais)\n",
    "        df.to_sql(name='COUNTRIES',con=con, if_exists='append', index=False)\n",
    "        \n",
    "        return(dic[country])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COUNTRIES(\"USA\")\n",
    "COUNTRIES(\"CHILE\")\n",
    "COUNTRIES(\"JAPAN\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 20px; color:cyan; font-weight: bold;\"> - Development of the Historic table. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_japan = f'https://earthquake.usgs.gov/fdsnws/event/1/query?format=csv&starttime=2010-01-01%2000:00:00&endtime=2023-12-31%2023:59:59&minlatitude=27.000000&maxlatitude=44.000000&minlongitude=132.780000&maxlongitude=145.530000&minmagnitude=3&orderby=time-asc&jsonerror=true'\n",
    "dt_in_jap=pd.read_csv(url_japan,delimiter=',')\n",
    "url_chile = f'https://earthquake.usgs.gov/fdsnws/event/1/query?format=csv&starttime=2010-01-01%2000:00:00&endtime=2023-12-31%2023:59:59&minlatitude=-56.800000&maxlatitude=-19.000000&minlongitude=-79.000000&maxlongitude=-69.&minmagnitude=3&orderby=time-asc&jsonerror=true'\n",
    "dt_in_ch=pd.read_csv(url_chile,delimiter=\",\")\n",
    "url_usa = f'https://earthquake.usgs.gov/fdsnws/event/1/query?format=csv&starttime=2010-01-01%2000:00:00&endtime=2023-12-31%2023:59:59&maxlatitude=50&minlatitude=24.6&maxlongitude=-65&minlongitude=-125&minmagnitude=3&orderby=time-asc&jsonerror=true'\n",
    "dt_in_usa=pd.read_csv(url_usa,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformar_fecha(dato):\n",
    "    fecha_sin_tz = dato.replace(\"T\", \" \").replace(\"Z\", \"\")\n",
    "    fecha_objeto = datetime.strptime(fecha_sin_tz, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    fecha_formateada = fecha_objeto.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "    return fecha_formateada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generat_dat (df,pais:str):\n",
    "    df[\"place\"]=df[\"place\"].fillna(\"no data\")\n",
    "    df=df.fillna(0)\n",
    "    df=df.drop_duplicates()\n",
    "    df=df[[\"mag\",\"place\",\"time\",\"longitude\",\"latitude\",\"depth\"]]\n",
    "    df['time'] = df['time'].apply(lambda x: transformar_fecha(x))\n",
    "    df.rename(columns={'latitude':'lat', 'longitude':'lng' }, inplace=True)\n",
    "    df[\"idcountry\"]=COUNTRIES(pais)\n",
    "    df[\"tsunami\"]=0\n",
    "    df[\"danger\"]=\"1\"\n",
    "    df=df[[\"idcountry\",\"mag\",\"place\",\"time\",\"tsunami\",\"lng\",\"lat\",\"depth\",\"danger\"]]\n",
    "    \n",
    "       \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_his_usa=generat_dat(dt_in_usa,\"USA\")\n",
    "dt_his_chil=generat_dat(dt_in_ch,\"CHILE\")\n",
    "dt_his_jap=generat_dat(dt_in_jap,\"JAPAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14715"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_his_usa.to_sql(name='USA',con=con, if_exists='append', index=False)\n",
    "dt_his_usa.to_sql(name='FACTS',con=con, if_exists='append', index=False)\n",
    "\n",
    "dt_his_chil.to_sql(name='CHILE',con=con, if_exists='append', index=False)\n",
    "dt_his_chil.to_sql(name='FACTS',con=con, if_exists='append', index=False)\n",
    "\n",
    "dt_his_jap.to_sql(name='JAPAN',con=con, if_exists='append', index=False)\n",
    "dt_his_jap.to_sql(name='FACTS',con=con, if_exists='append', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 20px; color:cyan; font-weight: bold;\"> - Generate data from tsunamis. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'https://www.ngdc.noaa.gov/hazel/hazard-service/api/v1/tsunamis/events?country=USA&maxYear=2023&minYear=2010'\n",
    "dt_usa_prev_Mar = pd.DataFrame(requests.get(url).json()['items'])\n",
    "\n",
    "url = f'https://www.ngdc.noaa.gov/hazel/hazard-service/api/v1/tsunamis/events?country=JAPAN&maxYear=2023&minYear=2010'\n",
    "dt_jap_prev_Mar = pd.DataFrame(requests.get(url).json()['items'])\n",
    "\n",
    "url = f'https://www.ngdc.noaa.gov/hazel/hazard-service/api/v1/tsunamis/events?country=CHILE&maxYear=2023&minYear=2010'\n",
    "dt_chi_prev_Mar = pd.DataFrame(requests.get(url).json()['items'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mar(df):\n",
    "    \n",
    "    df=df.fillna(0)\n",
    "    df['time'] = pd.to_datetime(df[['year','month','day','hour','minute','second']],format='%Y/%m/%d %H:%M:%S')\n",
    "    df['time'] =df['time'].apply(lambda x: x.strftime('%Y/%m/%d %H:%M:%S'))\n",
    "    df.rename(columns={'eqMagnitude':'mag', 'eqDepth':'depth', 'latitude':'lat', 'longitude':'lng',\n",
    "    'locationName':'place', 'maxWaterHeight':'mxwatheight'}, inplace=True)\n",
    "\n",
    "\n",
    "    df['mxwatheight']  = df.mxwatheight.astype('float64')\n",
    "    df.mag=df.mag.astype('float64')\n",
    "    df.lng=df.lng.astype('float64')\n",
    "    df.lat=df.lat.astype('float64')\n",
    "    df.depth=df.depth.astype('float64')\n",
    "\n",
    "    a=df[\"country\"][1]\n",
    "    df[\"idcountry\"]=COUNTRIES(a)\n",
    "    \n",
    "    # Filtramos el dataframe con los datos relevantes.\n",
    "    df = df[['idcountry','mxwatheight','place', 'time', 'mag', 'lng','lat', 'depth' ]]\n",
    "    \n",
    "    return (df)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_usa_Mar=mar(dt_usa_prev_Mar)\n",
    "dt_chi_Mar=mar(dt_chi_prev_Mar)\n",
    "dt_jap_Mar=mar(dt_jap_prev_Mar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_usa_Mar.to_sql(name='TSUNAMIS',con=con, if_exists='append', index=False)\n",
    "dt_chi_Mar.to_sql(name='TSUNAMIS',con=con, if_exists='append', index=False)\n",
    "dt_jap_Mar.to_sql(name='TSUNAMIS',con=con, if_exists='append', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 20px; color:cyan; font-weight: bold;\"> - Generate datatest from Sismos. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sismos_Noaa():\n",
    "\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "    from IPython.display import display\n",
    "    countries = ['USA', 'CHILE', 'JAPAN']\n",
    "    dt=pd.DataFrame(index=['idpais','mag','place', 'time','tsunami', 'lng','lat', 'deepth'])\n",
    "    for country in countries:\n",
    "        if country==\"USA\": z=1\n",
    "        elif country==\"CHILE\": z=2\n",
    "        elif country==\"JAPAN\": z=3\n",
    "        # Obtenemos información a partir de la API\n",
    "        url = f'https://www.ngdc.noaa.gov/hazel/hazard-service/api/v1/earthquakes?country={country}&maxYear=2023&minYear=2000'\n",
    "        df = pd.DataFrame(requests.get(url).json()['items'])\n",
    "\n",
    "        # Creamos la columna con la fecha del sismo\n",
    "        df['time'] = pd.to_datetime(df[['year','month','day','hour','minute','second']])\n",
    "\n",
    "        # Renombramos los features para normalizar con los otros datos recolectados\n",
    "        df.rename(columns={'eqMagnitude':'mag', 'eqDepth':'depth', 'latitude':'lat', 'longitude':'lng', 'locationName':'place', 'country':'pais'}, inplace=True)\n",
    "\n",
    "        # Creamos features adicionales para normalizar los datos.\n",
    "        df['url'] = url\n",
    "        df['title'] = None\n",
    "        df['tsunami'] = df.apply(lambda x: 1 if pd.isnull(x.tsunamiEventId) != True else 0, axis=1)\n",
    "        df['idcountry']  = z\n",
    "        df['place']  = df.apply(lambda x: x.place.lower(),axis=1)\n",
    "        \n",
    "        # Filtramos el dataframe con los datos relevantes.\n",
    "        df = df[['idcountry','mag','place', 'time','tsunami', 'lng','lat', 'depth']]\n",
    "        df['danger']=3\n",
    "        dt=pd.concat([dt,df],ignore_index=True)\n",
    "        dt= dt.dropna(how='all')\n",
    "        dt=dt.sort_values(\"time\", ascending=False)\n",
    "\n",
    "    return(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_sismo=sismos_Noaa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_sismo.to_sql(name='SISMOTEST',con=con, if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
>>>>>>> 3009424700371caddb7810c6f30216e4e5d69b74
